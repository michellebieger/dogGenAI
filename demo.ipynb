{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a generative AI with twinlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pickle\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# twinLab\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Uncomment this to use images of the numbers 0-9\n",
    "experiment = \"MNIST\"\n",
    "\n",
    "# Uncomment this to use images of objects from CIFAR-10 database \n",
    "# Data is from the website https://www.cs.toronto.edu/~kriz/cifar.html \n",
    "# experiment = \"CIFAR-10\"\n",
    "\n",
    "# Random numbers\n",
    "random_seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def unpickle(file): # Unpickle a CIFAR-10 file\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "def wrangle_image(linear_image, npix): # Reshape a CIFAR-10 image\n",
    "    pix = npix**2\n",
    "    if len(linear_image) == pix:\n",
    "        image = linear_image.reshape(npix, npix)\n",
    "    elif len(linear_image) == 3*pix:\n",
    "        R = linear_image[0*pix:1*pix].reshape(npix, npix)\n",
    "        G = linear_image[1*pix:2*pix].reshape(npix, npix)\n",
    "        B = linear_image[2*pix:3*pix].reshape(npix, npix)\n",
    "        image = np.dstack((R, G, B)).astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Image is neither 1D nor 3D.\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment == \"MNIST\":\n",
    "\n",
    "    # Read data in and set pixels that the training data has \n",
    "    # In this case, it's 8x8 pixel pictures of numbers 0 to 9. 1798 pictures\n",
    "    npix = 8\n",
    "    filepath = \"MNIST/data.csv\"\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "elif experiment == \"CIFAR-10\":\n",
    "\n",
    "    # 32x32 pixel pictures. 10 pictures of 10 different types of object \n",
    "    npix = 32\n",
    "    filepath = \"CIFAR-10/data_batch_1\"\n",
    "    data = unpickle(filepath)\n",
    "\n",
    "    df = pd.DataFrame(data[b\"data\"])\n",
    "    df.columns = [f\"{RGB}-{i}-{j}\" for RGB in [\"R\", \"G\", \"B\"] for i in range(npix) for j in range(npix)]\n",
    "    # Iterate through the RGB values that compose these pictures \n",
    "    # Each pixel gets a value so we can unpack a 3D object into the 2D dataframe\n",
    "    df[\"number\"] = data[b\"labels\"] #Â TODO: Try to insert this as the first column\n",
    "\n",
    "else:\n",
    "\n",
    "    raise ValueError(\"Experiement not recognised\")\n",
    "    # You've specified an experiment that doesn't exist!\n",
    "\n",
    "inputs = [\"number\"]\n",
    "outputs = list(df.drop(columns=inputs).columns)\n",
    "\n",
    "# Plot an image\n",
    "image = wrangle_image(df[outputs].iloc[0].to_numpy(), npix)\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(image, cmap=\"binary_r\")\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up campaign\n",
    "inputs = [\"number\"]\n",
    "outputs = list(df.drop(columns=['number']))\n",
    "setup_dict = {\n",
    "    \"inputs\": inputs,\n",
    "    \"outputs\": outputs,\n",
    "    'estimator': 'gaussian_process_regression', # What type of model do you want to use? \n",
    "    'decompose_outputs': True, # Equivalent of PCA/SVD for TL--on or off?\n",
    "    'output_explained_variance': 0.75 # Toggle this number to improve accuracy\n",
    "}\n",
    "\n",
    "campaign = tl.Campaign(**setup_dict)\n",
    "# Setting up parameters for TL campaign \n",
    "\n",
    "# Run campaign\n",
    "train_dict = {\n",
    "    \"df\": df,\n",
    "    \"train_test_split\": 200,\n",
    "    # Increase this number to increase the amount of data used to train the model\n",
    "}\n",
    "campaign.fit(**train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame({'number': list(range(10))})\n",
    "# df_predict = ['R00']\n",
    "# display(df_predict)\n",
    "# campaign.predict(df_predict)\n",
    "df_mean, _ = campaign.predict(df_predict)\n",
    "# Pull out the mean and true to the prediction of the campaign\n",
    "# Can also pull out the standard deviation (std)\n",
    "display(df_mean)\n",
    "\n",
    "# Plot the mean value of each figure/number from the trained dataset\n",
    "plt.subplots(2, 5, figsize=(10, 4))\n",
    "iplot = 0\n",
    "for row in range(10):\n",
    "    iplot += 1\n",
    "    plt.subplot(2,5,iplot)\n",
    "    image = wrangle_image(df_mean.iloc[row].to_numpy(), npix)\n",
    "    plt.imshow(image, cmap=\"binary_r\")\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "df_samples = campaign.sample(df_predict, n)\n",
    "display(df_samples)\n",
    "# Pull out random samples of each type of image from the trained dataset\n",
    "\n",
    "# Plot random samples of each type of image from the trained dataset:\n",
    "nrow, ncol = n, 10\n",
    "# npix should be 8\n",
    "plt.subplots(nrow, ncol, figsize=(10, 1*n))\n",
    "iplot = 0\n",
    "for sample in range(n):\n",
    "    for row in range(10):\n",
    "        iplot += 1\n",
    "        plt.subplot(nrow, ncol, iplot)\n",
    "        linear_image = df_samples.xs(row, axis=\"columns\", level=1, drop_level=True).iloc[sample].to_numpy()\n",
    "        image = wrangle_image(linear_image, npix)\n",
    "        plt.imshow(image, cmap=\"binary_r\")\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
